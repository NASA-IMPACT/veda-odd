{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b31628-5535-45a6-bf97-ba0a7568a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b6f0244-b7ca-4363-ab37-d77841635822",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'nasa-eodc-scratch'\n",
    "timechunks = '24'\n",
    "directory = f'NLDAS/netcdf/.timechunk{timechunks}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75ea3ec5-4f00-4917-97cb-8347813a20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = helpers.get_credentials()\n",
    "s3fsfs = helpers.create_s3filesystem(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b86d4d8c-5bc7-4aa1-b94d-44fd2d60f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 1.88 s, total: 5.29 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = s3fsfs.glob(f's3://{bucket}/{directory}/*.nc')\n",
    "ds = xr.open_dataset(s3fsfs.open(f's3://{files[0]}'))\n",
    "da = ds['Tair'].sel(lat=slice(40,62), lon=slice(-125, -103))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a388bd9-47aa-4fe2-81a8-9d853dbb62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunked_file(\n",
    "    da: xr.DataArray, \n",
    "    s3fsfs: s3fs.S3FileSystem,\n",
    "    bucket: str = 'nasa-eodc-scratch',\n",
    "    time_chunk=24, \n",
    "    lat=50, \n",
    "    lon=90, \n",
    "    variable_name='Tair',\n",
    "    output_dir='test_files',\n",
    "    upload_to_s3=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a NetCDF file with specified chunking and optionally upload to S3.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    da : xarray.DataArray\n",
    "        The input data array to be chunked.\n",
    "    bucket : str\n",
    "        S3 bucket name.\n",
    "    s3fsfs : s3fs.S3FileSystem\n",
    "        S3 filesystem object.\n",
    "    time_chunk : int, default 24\n",
    "        Number of time steps per chunk.\n",
    "    lat : int\n",
    "        Latitude chunk size.\n",
    "    lon : int\n",
    "        Longitude chunk size.\n",
    "    variable_name : str, default 'tair'\n",
    "        Name of the variable in the file.\n",
    "    output_dir : str, default 'chunking_test'\n",
    "        Directory in S3 bucket to store the file.\n",
    "    upload_to_s3 : bool, default True\n",
    "        Whether to upload the file to S3.\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress information.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with file paths and timing information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create chunks dictionary\n",
    "    chunks = {'time': time_chunk, 'lat': lat, 'lon': lon}\n",
    "    chunk_shape_as_string = ('_').join([f\"{k}{v}\" for k, v in chunks.items()])\n",
    "    \n",
    "    # Generate filename\n",
    "    filename = f\"{chunk_shape_as_string}_{variable_name}.nc\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Creating file with chunks: {chunks}\")\n",
    "        print(f\"Output filename: {filename}\")\n",
    "    \n",
    "    # Time the chunking and file writing process\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply chunking\n",
    "    chunked_da = da.chunk(chunks=chunks)\n",
    "    encoding = da.encoding.copy()\n",
    "    del encoding['source']\n",
    "    del encoding['original_shape']\n",
    "    del encoding['preferred_chunks']\n",
    "    encoding['chunksizes'] = tuple(chunks.values())\n",
    "    \n",
    "    # Write to NetCDF file\n",
    "    chunked_da.to_netcdf(filename, mode='w', encoding={variable_name: encoding})\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"File created in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    # Upload to S3 if requested\n",
    "    s3_path = None\n",
    "    \n",
    "    if upload_to_s3:\n",
    "        s3_path = f's3://{bucket}/NLDAS/netcdf/{output_dir}/{filename}'\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Uploading to {s3_path}...\")\n",
    "        \n",
    "        s3fsfs.put(filename, s3_path)\n",
    "    \n",
    "    # Return info about the file\n",
    "    return {\n",
    "        'local_path': os.path.abspath(filename),\n",
    "        's3_path': s3_path,\n",
    "        'chunks': chunks,\n",
    "        'file_size_mb': os.path.getsize(filename) / (1024 * 1024),\n",
    "        'processing_time': elapsed_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dda9d2af-ab7b-4406-9f2b-327f56fc2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_configurations = [\n",
    "    # 1 chunk for all time steps\n",
    "    dict(time_chunk=24, lat=45, lon=90), # 0.39MB\n",
    "    dict(time_chunk=24, lat=350, lon=700), # 23.52 MB\n",
    "    dict(time_chunk=24, lat=500, lon=1000), # 23.52 MB\n",
    "    dict(time_chunk=24, lat=1100, lon=2200), # 232.32 MB\n",
    "    # 6 timesteps per chunk\n",
    "    dict(time_chunk=6, lat=90, lon=180), # 0.39MB\n",
    "    dict(time_chunk=6, lat=700, lon=1400), # 12MB\n",
    "    dict(time_chunk=6, lat=2200, lon=2200), # 116.16 MB\n",
    "    # 1 timestep per chunk\n",
    "    dict(time_chunk=1, lat=225, lon=450), # 0.4MB\n",
    "    dict(time_chunk=1, lat=1000, lon=2000), # 8MB\n",
    "    dict(time_chunk=1, lat=2200, lon=2200), # 19.36 MB\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad78a637-f3b4-4889-851b-b47baea6fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file with chunks: {'time': 24, 'lat': 45, 'lon': 90}\n",
      "Output filename: time24_lat45_lon90_Tair.nc\n",
      "File created in 60.15 seconds\n",
      "Uploading to s3://nasa-eodc-scratch/NLDAS/netcdf/test_files/time24_lat45_lon90_Tair.nc...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_path': '/home/jovyan/veda-odd/nldas_benchmarking/01_create_intake_stac/time24_lat45_lon90_Tair.nc',\n",
       " 's3_path': 's3://nasa-eodc-scratch/NLDAS/netcdf/test_files/time24_lat45_lon90_Tair.nc',\n",
       " 'chunks': {'time': 24, 'lat': 45, 'lon': 90},\n",
       " 'file_size_mb': 216.09884071350098,\n",
       " 'processing_time': 60.152421712875366}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_chunked_file(da, s3fsfs, **chunk_configurations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0eeade3-f4a4-4537-8b9a-d0cbde835924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file with chunks: {'time': 1, 'lat': 225, 'lon': 450}\n",
      "Output filename: time1_lat225_lon450_Tair.nc\n",
      "File created in 244.13 seconds\n",
      "Uploading to s3://nasa-eodc-scratch/NLDAS/netcdf/test_files/time1_lat225_lon450_Tair.nc...\n",
      "Creating file with chunks: {'time': 1, 'lat': 1000, 'lon': 2000}\n",
      "Output filename: time1_lat1000_lon2000_Tair.nc\n",
      "File created in 578.12 seconds\n",
      "Uploading to s3://nasa-eodc-scratch/NLDAS/netcdf/test_files/time1_lat1000_lon2000_Tair.nc...\n",
      "Creating file with chunks: {'time': 1, 'lat': 2200, 'lon': 2200}\n",
      "Output filename: time1_lat2200_lon2200_Tair.nc\n",
      "File created in 356.01 seconds\n",
      "Uploading to s3://nasa-eodc-scratch/NLDAS/netcdf/test_files/time1_lat2200_lon2200_Tair.nc...\n"
     ]
    }
   ],
   "source": [
    "for config in chunk_configurations[-3:]:\n",
    "    create_chunked_file(da=da, s3fsfs=s3fsfs, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39d7f76f-95df-432a-b3c7-f79515c26997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = 'time6_lat2200_lon2200_Tair.nc'\n",
    "# output_dir = 'test_files'\n",
    "# s3_path = f's3://{bucket}/NLDAS/netcdf/{output_dir}/{filename}'\n",
    "\n",
    "# s3fsfs.put(filename, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f8edcad-e593-411e-8b29-8622f392b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan jovyan 217M May 16 19:09 time24_lat45_lon90_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 219M May 16 19:15 time24_lat350_lon700_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 219M May 16 19:25 time24_lat500_lon1000_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 219M May 16 19:35 time24_lat1100_lon2200_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 218M May 16 19:37 time6_lat90_lon180_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 220M May 16 19:47 time6_lat700_lon1400_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 219M May 16 19:58 time6_lat2200_lon2200_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 219M May 16 20:11 time1_lat225_lon450_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 221M May 16 20:21 time1_lat1000_lon2000_Tair.nc\n",
      "-rw-r--r-- 1 jovyan jovyan 219M May 16 20:27 time1_lat2200_lon2200_Tair.nc\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr -h *Tair.nc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
